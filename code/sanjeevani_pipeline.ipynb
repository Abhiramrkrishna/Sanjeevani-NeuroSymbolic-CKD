{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Install dependencies**","metadata":{}},{"cell_type":"code","source":"!pip install -q -U transformers accelerate bitsandbytes gradio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T23:51:01.360473Z","iopub.execute_input":"2026-02-24T23:51:01.360736Z","iopub.status.idle":"2026-02-24T23:51:18.504081Z","shell.execute_reply.started":"2026-02-24T23:51:01.360706Z","shell.execute_reply":"2026-02-24T23:51:18.502873Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.7/60.7 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**Logs into hugging face.**","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport random\nimport io\nimport numpy as np\nimport scipy.signal\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport transformers\nfrom transformers import AutoProcessor, PaliGemmaForConditionalGeneration, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport gradio as gr\n\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\n\n# --- CONFIGURATION & AUTHENTICATION ---\nSEED = 42\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything(SEED)\ntransformers.logging.set_verbosity_error()\n\ntry:\n    user_secrets = UserSecretsClient()\n    hf_token = user_secrets.get_secret(\"HF_TOKEN\") \n    login(token=hf_token)\n    print(f\"‚úÖ Successfully Logged into Hugging Face! Pipeline Online ({DEVICE})\")\nexcept Exception as e:\n    print(\"‚ö†Ô∏è Could not log in. Ensure your Kaggle Secret is named 'HF_TOKEN'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T23:52:08.943270Z","iopub.execute_input":"2026-02-24T23:52:08.943514Z","iopub.status.idle":"2026-02-24T23:52:38.431292Z","shell.execute_reply.started":"2026-02-24T23:52:08.943489Z","shell.execute_reply":"2026-02-24T23:52:38.430393Z"}},"outputs":[{"name":"stdout","text":"‚ö†Ô∏è Could not log in. Ensure your Kaggle Secret is named 'HF_TOKEN'.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**Neuro-Symbolic Architecture & Generators** : It defines the Physics engine and biological distributions. ","metadata":{}},{"cell_type":"code","source":"# =================================================================\n# ADVANCED HDR PREPROCESSING & DATA GENERATION\n# =================================================================\ndef dynamic_scaling_advanced(signal_tensor, window_size=51):\n    pad = window_size // 2\n    local_max = F.max_pool1d(signal_tensor, kernel_size=window_size, stride=1, padding=pad)\n    local_min = -F.max_pool1d(-signal_tensor, kernel_size=window_size, stride=1, padding=pad)\n    \n    global_max = signal_tensor.max(dim=-1, keepdim=True)[0]\n    noise_floor = torch.clamp(global_max * 0.02, min=1e-6)\n    \n    raw_contrast = local_max - local_min\n    local_contrast = torch.maximum(raw_contrast, noise_floor)\n    return (signal_tensor - local_min) / local_contrast\n\nclass CKDMetabolomeGenerator:\n    def __init__(self, seed=42):\n        self.rng = np.random.RandomState(seed)\n        self.ppm_axis = np.linspace(0, 10, 1000)\n    \n    def pseudo_voigt(self, x, center, amp, width, eta=0.6):\n        sigma = width / (2 * np.sqrt(2 * np.log(2)))\n        gamma = width / 2\n        g = np.exp(-(x - center)**2 / (2 * sigma**2 + 1e-8))\n        l = 1 / (1 + ((x - center) / (gamma + 1e-8))**2)\n        return amp * (eta * l + (1 - eta) * g)\n\n    def generate_batch(self, n_samples=100):\n        inputs, targets_cls, targets_reg, labels = [], [], [], []\n        \n        for _ in range(n_samples):\n            is_sick = self.rng.choice([0, 1])\n            ph_shift = self.rng.uniform(-0.03, 0.03) \n            cr_amp = self.rng.uniform(0.8, 1.2)\n            \n            if is_sick:\n                cit_ratio = np.clip(self.rng.normal(0.4, 0.2), 0.1, 0.8)   \n                lac_ratio = np.clip(self.rng.normal(1.2, 0.3), 0.7, 2.0)   \n                tmao_ratio = np.clip(self.rng.normal(1.0, 0.3), 0.5, 1.8)  \n                tau_ratio = np.clip(self.rng.normal(0.2, 0.1), 0.05, 0.5)  \n            else:\n                cit_ratio = np.clip(self.rng.normal(1.0, 0.3), 0.5, 1.8)   \n                lac_ratio = np.clip(self.rng.normal(0.4, 0.2), 0.1, 0.9)   \n                tmao_ratio = np.clip(self.rng.normal(0.3, 0.2), 0.0, 0.8)  \n                tau_ratio = np.clip(self.rng.normal(0.8, 0.2), 0.4, 1.2)   \n            \n            sig_cr = self.pseudo_voigt(self.ppm_axis, 3.05 + ph_shift, cr_amp, 0.03) + \\\n                     self.pseudo_voigt(self.ppm_axis, 4.05 + ph_shift, cr_amp*0.8, 0.03)\n            sig_cit = self.pseudo_voigt(self.ppm_axis, 2.55 + ph_shift, cr_amp * cit_ratio, 0.04) + \\\n                      self.pseudo_voigt(self.ppm_axis, 2.68 + ph_shift, cr_amp * cit_ratio, 0.04)\n            sig_lac = self.pseudo_voigt(self.ppm_axis, 1.33 + ph_shift, cr_amp * lac_ratio, 0.035)\n            sig_tmao = self.pseudo_voigt(self.ppm_axis, 3.26 + ph_shift, cr_amp * tmao_ratio, 0.03)\n            sig_tau = self.pseudo_voigt(self.ppm_axis, 3.30 + ph_shift, cr_amp * tau_ratio, 0.05) + \\\n                      self.pseudo_voigt(self.ppm_axis, 3.42 + ph_shift, cr_amp * tau_ratio, 0.05)\n\n            n_decoys = self.rng.randint(5, 15) \n            decoy_signal = np.zeros_like(self.ppm_axis)\n            exclusion_zones = [(2.45, 2.75), (1.20, 1.50), (2.95, 3.15), (3.95, 4.15), (3.20, 3.32), (3.26, 3.48)]\n            \n            for _ in range(n_decoys):\n                for attempt in range(20):\n                    decoy_ppm = self.rng.uniform(0.5, 9.5)\n                    in_exclusion = any(lo <= decoy_ppm <= hi for lo, hi in exclusion_zones)\n                    if not in_exclusion: break\n                decoy_amp = self.rng.uniform(0.05, 0.15) \n                decoy_width = self.rng.uniform(0.02, 0.06)\n                decoy_signal += self.pseudo_voigt(self.ppm_axis, decoy_ppm, decoy_amp, decoy_width)\n            \n            is_flat_baseline = self.rng.rand() > 0.5\n            if is_flat_baseline:\n                protein_baseline = np.zeros_like(self.ppm_axis)\n            else:\n                protein_baseline = 0.5 * np.sin(self.ppm_axis * 0.8) if is_sick else 0.1 * np.sin(self.ppm_axis * 0.5)\n\n            raw_mix = sig_cr + sig_cit + sig_lac + sig_tmao + sig_tau + decoy_signal + protein_baseline\n            phase = self.rng.uniform(-0.1, 0.1)\n            dispersion = np.imag(scipy.signal.hilbert(raw_mix))\n            distorted = raw_mix * np.cos(phase) + dispersion * np.sin(phase)\n            \n            is_qc_fail = self.rng.rand() < 0.1 \n            if is_qc_fail: distorted = self.rng.normal(0, 0.5, 1000) \n            noisy_input = distorted + self.rng.normal(0, 0.02, 1000)\n\n            t_cls, t_reg = np.zeros((5, 1000)), np.zeros((5, 1000))\n            signals = [sig_cr, sig_cit, sig_lac, sig_tmao, sig_tau]\n            for c, sig in enumerate(signals):\n                if not is_qc_fail:\n                    mask = sig > (0.1 * sig.max() + 1e-6)\n                    t_cls[c, mask] = 1.0\n                    t_reg[c] = sig \n\n            inputs.append(noisy_input); targets_cls.append(t_cls); targets_reg.append(t_reg); labels.append(is_sick)\n            \n        return np.array(inputs), np.array(targets_cls), np.array(targets_reg), np.array(labels), self.ppm_axis\n\n# =================================================================\n# DEEP LEARNING ARCHITECTURE\n# =================================================================\nclass InceptionBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.branch1 = nn.Conv1d(in_channels, out_channels//4, kernel_size=1)\n        self.branch2 = nn.Conv1d(in_channels, out_channels//4, kernel_size=3, padding=1)\n        self.branch3 = nn.Conv1d(in_channels, out_channels//4, kernel_size=5, padding=2)\n        self.branch4 = nn.Conv1d(in_channels, out_channels//4, kernel_size=7, padding=3)\n        self.bn = nn.BatchNorm1d(out_channels)\n    def forward(self, x):\n        out = torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], dim=1)\n        return F.leaky_relu(self.bn(out), 0.1)\n\nclass SanjeevaniEngine(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.enc1 = InceptionBlock(1, 32)\n        self.pool = nn.MaxPool1d(2)\n        self.enc2 = InceptionBlock(32, 64)\n        encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=4, dim_feedforward=256, batch_first=True)\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n        self.decoders = nn.ModuleList([\n            nn.Sequential(\n                nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n                nn.BatchNorm1d(32),\n                nn.LeakyReLU(0.1)\n            ) for _ in range(5)\n        ])\n        self.heads_cls = nn.ModuleList([nn.ConvTranspose1d(32, 1, kernel_size=4, stride=2, padding=1) for _ in range(5)])\n        self.heads_reg = nn.ModuleList([nn.ConvTranspose1d(32, 1, kernel_size=4, stride=2, padding=1) for _ in range(5)])\n        \n    def forward(self, x):\n        x = self.pool(self.enc1(x))\n        x = self.pool(self.enc2(x))\n        x = x.permute(0, 2, 1)\n        x = self.transformer(x)\n        x = x.permute(0, 2, 1)\n        cls_outputs, reg_outputs = [], []\n        for i in range(5):\n            dec = self.decoders[i](x)\n            cls_outputs.append(self.heads_cls[i](dec))\n            reg_outputs.append(F.relu(self.heads_reg[i](dec)))\n        return torch.cat(cls_outputs, dim=1), torch.cat(reg_outputs, dim=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Training the Physics Engine**","metadata":{}},{"cell_type":"code","source":"print(\"\\nüöÄ Training Custom Physics Engine (Sanjeevani V1)...\")\n\ngen = CKDMetabolomeGenerator(seed=42)\nX, Y_cls, Y_reg, Y_labels, ppm = gen.generate_batch(10000)\n\nX_t = torch.tensor(X, dtype=torch.float32).unsqueeze(1).to(DEVICE)\nY_cls_t = torch.tensor(Y_cls, dtype=torch.float32).to(DEVICE)\nY_reg_t = torch.tensor(Y_reg, dtype=torch.float32).to(DEVICE)\nX_t = dynamic_scaling_advanced(X_t)\n\nmodel = SanjeevaniEngine().to(DEVICE)\noptimizer = optim.Adam(model.parameters(), lr=0.0005)\n\ncrit_cls = nn.BCEWithLogitsLoss(reduction='none') \ncrit_reg = nn.MSELoss(reduction='none')\nchannel_weights = torch.tensor([1.0, 2.0, 3.0, 5.0, 2.0], dtype=torch.float32).to(DEVICE)\nw = channel_weights.view(1, 5, 1)\n\nmodel.train()\nBATCH_SIZE = 64\nn_batches = len(X) // BATCH_SIZE\n\nfor epoch in range(25):\n    epoch_loss = 0\n    indices = torch.randperm(len(X))\n    for i in range(n_batches):\n        batch_idx = indices[i*BATCH_SIZE : (i+1)*BATCH_SIZE]\n        optimizer.zero_grad()\n        pred_cls, pred_reg = model(X_t[batch_idx])\n        loss_cls = (crit_cls(pred_cls, Y_cls_t[batch_idx]) * w).mean()\n        loss_reg = (crit_reg(pred_reg, Y_reg_t[batch_idx]) * w).mean()\n        loss = loss_cls + loss_reg\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    if (epoch+1)%5==0: \n        print(f\"   Epoch {epoch+1}: Loss {epoch_loss/n_batches:.4f}\")\n\ntorch.save(model.state_dict(), \"sanjeevani_engine.pth\")\ndel model, optimizer, X, Y_cls, Y_reg, X_t, Y_cls_t, Y_reg_t\ngc.collect(); torch.cuda.empty_cache()\nprint(\"üíæ Physics Engine weights saved successfully.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Loading HAI-DEF Agents**: It safely spreads your VLMs and LLMs across the two T4 GPUs to prevent crashing.","metadata":{}},{"cell_type":"code","source":"print(\"üßπ Aggressive RAM Clearance...\")\ngc.collect()\ntorch.cuda.empty_cache()\n\nbnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n\nprint(\"‚è≥ Loading Physics Engine to GPU 0...\")\nmodel = SanjeevaniEngine().to(\"cuda:0\") \nmodel.load_state_dict(torch.load(\"sanjeevani_engine.pth\"))\nmodel.eval()\n\nprint(\"‚è≥ Loading Vision Agent (PaliGemma) onto GPU 0...\")\npg_processor = AutoProcessor.from_pretrained(\"google/paligemma-3b-mix-224\")\npg_model = PaliGemmaForConditionalGeneration.from_pretrained(\n    \"google/paligemma-3b-mix-224\",\n    quantization_config=bnb_config,\n    device_map={\"\": 0},\n    low_cpu_mem_usage=True\n)\n\ngc.collect() \n\nprint(\"‚è≥ Loading Clinical Agent (MedGemma) onto GPU 1...\")\ntokenizer = AutoTokenizer.from_pretrained(\"google/medgemma-1.5-4b-it\")\nclinical_model = AutoModelForCausalLM.from_pretrained(\n    \"google/medgemma-1.5-4b-it\",\n    quantization_config=bnb_config,\n    device_map={\"\": 1},\n    low_cpu_mem_usage=True\n)\n\nprint(\"‚úÖ ALL MODELS LOADED SUCCESSFULLY AND READY FOR UI!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Launching Sanjeevani UI**: This launches the fully deterministic Gradio app.","metadata":{}},{"cell_type":"code","source":"print(\"üöÄ Initializing Sanjeevani Clinical Dashboard...\")\n\ndemo_cases = {}\ngen_ui = CKDMetabolomeGenerator(seed=42)\nX_pool, _, _, Y_pool, ppm = gen_ui.generate_batch(100) \n\nfor i in range(100):\n    if Y_pool[i] == 0 and X_pool[i].max() > 0.7:\n        demo_cases[\"Patient A (Healthy Routine Screening)\"] = {\n            \"signal\": X_pool[i], \n            \"profile\": \"45-year-old male. Routine rural screening. No prior history of kidney disease. Blood pressure normal.\"\n        }\n        break\n\nfor i in range(100):\n    if Y_pool[i] == 1 and X_pool[i].max() > 0.7:\n        demo_cases[\"Patient B (Type 2 Diabetic - High Risk)\"] = {\n            \"signal\": X_pool[i], \n            \"profile\": \"62-year-old female. Type 2 Diabetes for 10 years. Complains of fatigue. Recent eGFR shows mild decline.\"\n        }\n        break\n\nnoise_signal = np.random.normal(0, 0.2, 1000)\ndemo_cases[\"Patient C (Degraded Sample / Noise)\"] = {\n    \"signal\": noise_signal, \n    \"profile\": \"70-year-old male. Urine sample delayed in transit for 48 hours without refrigeration.\"\n}\n\ndef run_sanjeevani_pipeline(patient_selection):\n    case_data = demo_cases[patient_selection]\n    signal_real = case_data[\"signal\"]\n    profile = case_data[\"profile\"]\n    \n    # --- STAGE 1: PALI-GEMMA VISION QC ---\n    plt.figure(figsize=(4, 4), dpi=100)\n    plt.plot(ppm, signal_real, color='black', linewidth=1)\n    plt.axvspan(3.0, 4.1, color='green', alpha=0.3) \n    plt.xlim(2.5, 4.5); plt.ylim(signal_real.min() - 0.2, signal_real.max() + 0.2)\n    plt.axis('off')\n    \n    buf = io.BytesIO()\n    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n    plt.close()\n    buf.seek(0)\n    qc_img = Image.open(buf).convert(\"RGB\")\n    \n    prompt = \"<image>answer en classify the signal inside the green box: 'sharp peaks' or 'flat noise'?\"\n    inputs = pg_processor(text=prompt, images=qc_img, return_tensors=\"pt\").to(pg_model.device)\n    with torch.no_grad():\n        gen_ids = pg_model.generate(**inputs, max_new_tokens=10)\n        finding = pg_processor.decode(gen_ids[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True).strip().lower()\n    \n    is_qc_failed = \"noise\" in finding\n    \n    # --- STAGE 2: SANJEEVANI PHYSICS ENGINE ---\n    x_tensor = torch.tensor(signal_real, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(\"cuda:0\")\n    with torch.no_grad():\n        _, p_reg = model(dynamic_scaling_advanced(x_tensor))\n        reg = p_reg.cpu().squeeze().numpy()\n        \n    cr_amp_raw = reg[0, 300:415].max()\n    cit_amp_raw = reg[1, 245:280].max()\n    lac_amp_raw = reg[2, 125:145].max()\n    tmao_amp_raw = reg[3, 315:335].max()\n    \n    cr_anchor = cr_amp_raw + 1e-6 \n    cit_ratio = cit_amp_raw / cr_anchor\n    lac_ratio = lac_amp_raw / cr_anchor\n    tmao_ratio = tmao_amp_raw / cr_anchor\n\n    cit_deficit = max(0, 1.0 - cit_ratio) \n    risk_score = (cit_deficit * 1.5) + (tmao_ratio * 1.0) + (lac_ratio * 0.8)\n\n    CR_THRESHOLD = 0.01 \n    if is_qc_failed or cr_amp_raw < CR_THRESHOLD or (lac_ratio == 0.0 and tmao_ratio == 0.0):\n        pipeline_status = \"‚ùå INCONCLUSIVE (QC FAILURE)\"\n        ratios_display = \"Biomarker Math Halted: Data integrity compromised.\"\n    elif risk_score > 1.0:\n        pipeline_status = \"‚ö†Ô∏è HIGH RISK (SICK DETECTED)\"\n        ratios_display = f\"**Risk Score:** {risk_score:.2f} (Threshold: 1.0)\\n* Citrate Ratio: {cit_ratio:.2f}\\n* TMAO Ratio: {tmao_ratio:.2f}\\n* Lactate Ratio: {lac_ratio:.2f}\"\n    else:\n        pipeline_status = \"‚úÖ LOW RISK (HEALTHY)\"\n        ratios_display = f\"**Risk Score:** {risk_score:.2f} (Threshold: 1.0)\\n* Citrate Ratio: {cit_ratio:.2f}\\n* TMAO Ratio: {tmao_ratio:.2f}\\n* Lactate Ratio: {lac_ratio:.2f}\"\n\n    # --- STAGE 3: MEDGEMMA SYNTHESIS ---\n    if \"INCONCLUSIVE\" in pipeline_status:\n        doc_text = \"ERROR: Sample quality check failed. The PaliGemma Vision Agent or the Mathematical Anchor Gate detected missing anchor peaks or extreme baseline distortion.\"\n        patient_text = \"Drafting halted. Please request a new sample.\"\n    else:\n        cit_status = \"Depleted (Abnormal)\" if cit_ratio < 0.8 else \"Normal\"\n        # tmao_status = \"Elevated (Abnormal)\" if tmao_ratio > 0.5 else \"Normal\"\n        lac_status = \"Elevated (Abnormal)\" if lac_ratio > 0.6 else \"Normal\"\n\n        # Handle the non-detection edge case\n        if tmao_ratio < 0.05:\n            tmao_status = \"Not Detected (Exclude from clinical reasoning)\"\n        elif tmao_ratio > 0.5:\n            tmao_status = \"Elevated (Abnormal)\"\n        else:\n            tmao_status = \"Normal\"\n        doc_prompt = f\"\"\"You are an expert Nephrologist. Review the following urinary NMR deconvolution metrics. Do not write code.\nPatient Profile: {profile}\n\nBiomarker Status:\n- Citrate Ratio: {cit_ratio:.2f} ({cit_status})\n- TMAO Ratio: {tmao_ratio:.2f} ({tmao_status})\n- Lactate Ratio: {lac_ratio:.2f} ({lac_status})\n\nTask: Write a concise, professional Clinical Assessment and Plan in a single short paragraph (maximum 4 sentences). Do NOT use bullet points or lists.\n- Explicitly state which biomarkers are abnormal and explain their pathophysiological implications in the context of the patient's history.\n- Conclude with a specific clinical next step.\nAssessment and Plan:\"\"\"\n        \n        inputs_doc = tokenizer(doc_prompt, return_tensors=\"pt\").to(\"cuda:1\")\n        with torch.no_grad():\n            out_doc = clinical_model.generate(**inputs_doc, max_new_tokens=400) \n            doc_text = tokenizer.decode(out_doc[0], skip_special_tokens=True).replace(doc_prompt, \"\").strip()\n            doc_text = doc_text.split(\"Critique\")[0].split(\"Note:\")[0].strip()\n\n        pt_prompt = f\"\"\"You are a compassionate doctor messaging this patient directly through a secure hospital portal. Do not write code.\nPatient History: \"{profile}\"\n\nTask: Translate the following Doctor's Assessment and Plan into a short, warm, and natural-sounding message (3-4 sentences) to the patient.\n- Address them directly (\"You\").\n- Accurately reflect the exact level of concern and the specific next steps recommended in the Doctor's note.\n- Do NOT mention specific chemicals, metabolites, numbers, or use repetitive phrasing.\n\nDoctor's Assessment and Plan to Translate:\n{doc_text}\n\nMessage:\"\"\"\n        \n        inputs_pt = tokenizer(pt_prompt, return_tensors=\"pt\").to(\"cuda:1\")\n        with torch.no_grad():\n            out_pt = clinical_model.generate(**inputs_pt, max_new_tokens=150) \n            patient_text = tokenizer.decode(out_pt[0], skip_special_tokens=True).replace(pt_prompt, \"\").strip()\n            patient_text = patient_text.split(\"Critique\")[0].split(\"Note:\")[0].strip()\n\n    return qc_img, f\"**VLM Agent Output:** '{finding}'\", pipeline_status, ratios_display, doc_text, patient_text\n\n# --- GRADIO UI LAYOUT ---\nwith gr.Blocks(theme=gr.themes.Soft()) as demo:\n    gr.Markdown(\"# üè• Sanjeevani Clinical Dashboard\")\n    gr.Markdown(\"Automated CKD Triage and EMR Auto-Drafting via Neuro-Symbolic AI\")\n    \n    with gr.Row():\n        patient_dropdown = gr.Dropdown(choices=list(demo_cases.keys()), label=\"Select Incoming Patient File\", value=list(demo_cases.keys())[0], scale=3)\n        submit_btn = gr.Button(\"‚ñ∂Ô∏è Execute Sanjeevani Pipeline\", variant=\"primary\", scale=1)\n    \n    with gr.Tabs():\n        with gr.TabItem(\"üî¨ 1. Lab Diagnostics (AI Physics)\"):\n            with gr.Row():\n                with gr.Column():\n                    gr.Markdown(\"### PaliGemma Vision Gatekeeper\")\n                    img_output = gr.Image(label=\"Anchor Region Extract (2.5-4.5 ppm)\", height=300)\n                    vlm_output = gr.Markdown()\n                with gr.Column():\n                    gr.Markdown(\"### Neuro-Symbolic Math Engine\")\n                    status_output = gr.Markdown(\"## Awaiting execution...\")\n                    ratios_output = gr.Markdown()\n                    \n        with gr.TabItem(\"ü©∫ 2. Clinical Co-Pilot (Physician View)\"):\n            gr.Markdown(\"### MedGemma Synthesis\")\n            gr.Markdown(\"*Automated synthesis of mathematical ratios and patient history into a standard Assessment & Plan.*\")\n            doc_output = gr.Textbox(label=\"Generated Clinical Notes\", lines=6)\n            \n        with gr.TabItem(\"üì± 3. EMR Export (Patient Portal Draft)\"):\n            gr.Markdown(\"### MyChart / Patient Portal Auto-Draft\")\n            gr.Markdown(\"*MedGemma translation of the clinical notes for direct export to patient communication systems.*\")\n            patient_output = gr.Textbox(label=\"Patient-Friendly Message Draft\", lines=6)\n\n    submit_btn.click(\n        fn=run_sanjeevani_pipeline,\n        inputs=patient_dropdown,\n        outputs=[img_output, vlm_output, status_output, ratios_output, doc_output, patient_output]\n    )\n\ndemo.launch(share=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}